
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"I am a graduate student pursuing an MS in Computer Science at the University of Massachusetts (UMass) Amherst. Previously, I’ve interned at the Indian Institute of Technology (IIT) Bombay, working under the guidance of Prof. Ganesh Ramakrishnan and Dr. Venkatapathy Subramanian. During my undergraduate studies at K.J. Somaiya College of Engineering (KJSCE), I worked as a Research Assistant for Prof. Ninad Mehendale. Additionally, I collaborated with Prof. Deepak Sharma (Vice Principal of KJSCE) on two research projects.\nMy research interests primarily revolve around Computer Vision, with a specific focus on the application of Artificial Intelligence in healthcare and medical diagnosis. I am also intrigued by the intersection of Natural Language Processing and Computer Vision in fields such as Medical Image Report Generation and Document Image Translation.\nIn my free time, I enjoy playing basketball.\n","date":1670025600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1670025600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am a graduate student pursuing an MS in Computer Science at the University of Massachusetts (UMass) Amherst. Previously, I’ve interned at the Indian Institute of Technology (IIT) Bombay, working under the guidance of Prof.","tags":null,"title":"Utsavi Jiten Visaria","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://example.com/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Kush Vora","Utsavi Jiten Visaria","Darshil Mehta","Deepak Sharma"],"categories":null,"content":"","date":1670025600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1670025600,"objectID":"732925cee2f37e1f595512de2775971c","permalink":"https://example.com/publication/dysarthria/","publishdate":"2022-12-03T00:00:00Z","relpermalink":"/publication/dysarthria/","section":"publication","summary":"Dysarthria is a speech problem acquired at birth due to cerebral palsy (CP) or developed after severe brain damage. Dysarthria affects more than 70% of Parkinson's patients and 10% to 65% of people with traumatic brain injury. It is critical to detect dysarthria and other voice speech difficulties early to diagnose the underlying cause. Intelligent systems capable of identifying dysarthria with incredible precision have been developed using audio processing techniques and various deep learning models. This paper presents a hybrid CNN-LSTM model for classifying patients with dysarthria using audio recordings. The CNN-LSTM combination helps capture spatial and temporal information where CNN acts as a feature extractor while LSTM functions as a classifier. The proposed model was trained on the publicly available 9184 audio recordings from the TORGO dataset, and various audio augmentation techniques were employed to generate synthetic data. A total of 128 features were extracted using Mel Frequency Cepstral Coefficients (MFCC) and fed into the architecture as inputs. The K-fold cross-validation technique was used to avoid overfitting and increase the generalization capability of the model. The proposed architecture achieved a state-of-the-art 99.59% accuracy on the dataset. The presented work will minimize the workload of speech pathologists and help them detect dysarthria precisely and effectively.","tags":[],"title":"Hybrid CNN-LSTM network to detect Dysarthria using Mel-Frequency Cepstral Coefficients","type":"publication"},{"authors":["Utsavi Jiten Visaria","Kush Vora","Deepak Sharma"],"categories":null,"content":"","date":1669939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669939200,"objectID":"de6f7679af8d63a07da614ea9978759b","permalink":"https://example.com/publication/dental/","publishdate":"2022-12-02T00:00:00Z","relpermalink":"/publication/dental/","section":"publication","summary":"Dental disorders can lead to serious implications such as heart attack or strokes if not diagnosed and treated early. The diagnosis of these disorders differs from dentist to dentist due to differences in perception, poor x-ray quality because of noise, and different types of patients. As a result, there is an urgent need to create automated, AI-driven diagnostic solutions for dental disorders. Deep learning solutions have shown outstanding results in automated medical image analysis tasks. Our work proposes a U-Net with attention blocks to segment teeth from dental panoramic X-rays. The proposed Attention U-Net consists of four encoding and decoding blocks and achieved Dice Coefficient, IOU score, Specificity, and F1 Score of 0.9318, 0.8724, 0.9910, and 0.9379, respectively. The Attention U-Net achieves a 1.7% better Dice Coefficient score and 2.9% better IOU (Intersection Over Union) score than one of the best segmentation models, the U-Net. The segmented output can be used in computer-aided diagnostic (CAD) systems to detect various mouth disorders, helping the dentist diagnose the problem efficiently and accurately.","tags":null,"title":"An Attention U-Net for Semantic Segmentation of Dental Panoramic X-ray images","type":"publication"},{"authors":["Utsavi Jiten Visaria","Kush Vora","Darshil Mehta","Ninad Mehendale"],"categories":null,"content":"","date":1669161600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669161600,"objectID":"573619df0691820565501dc29ba3ccde","permalink":"https://example.com/publication/breast_tumor/","publishdate":"2022-11-23T00:00:00Z","relpermalink":"/publication/breast_tumor/","section":"publication","summary":"Breast cancer is one of the most common cancer types, and treatment largely depends on early detection. A person has a 13% (1 in 8 risks) of developing breast cancer at some time in their lives. Computer-aided diagnostic (CAD) systems powered by deep learning algorithms have enabled data analysis at high rates without compromising performance. Our work proposes an Enhanced EfficientNet (EEF-Net) for determining the severity of breast cancer through mammograms. EEF-Net is built on top of EfficientNet and has been fine-tuned to classify mammograms into three classes: benign, malignant, and healthy. The architecture was trained using the publicly accessible MIAS dataset, and a sophisticated image pre-processing pipeline was used to remove noise and other artifacts from the mammograms. The model achieved state-of-the-art results in the classification of breast cancer, achieving an accuracy of 97.14%, 98.67% sensitivity, 99.30% specificity, and 98.30% precision. EEF-Net will assist radiologists in mass screening patients with high precision and will minimize the radiologists' workload.","tags":[],"title":"EEF-Net: An Enhanced EfficientNet for Breast Tumor Classification in Mammograms","type":"publication"},{"authors":["Darshil Mehta","Utsavi Jiten Visaria","Kush Vora","Ninad Mehendale"],"categories":null,"content":"","date":1668470400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668470400,"objectID":"c132fa658c2fe7799fdfd5d8fab1a046","permalink":"https://example.com/publication/denoising/","publishdate":"2022-11-15T00:00:00Z","relpermalink":"/publication/denoising/","section":"publication","summary":"Brain tumors are one of the leading causes of death, and hence it is critical to diagnose them early. MRI is the most effective diagnostic tool for detecting a tumor. However, thermal noise, temperature fluctuations, and other artifacts can generate noisy MRI scans, leading to inaccurate diagnoses. Deep learning algorithms combined with image processing techniques have aided in a variety of medical imaging tasks, including enhancing MRI images. Our work proposes a U-Net architecture with two encoder-decoder pairs for denoising MRI scans which were finely tuned on a dataset generated by injecting synthetic Gaussian noise. The model improved the Peak Signal to Noise Ratio (PSNR) from 11.90 to 30.96. The presented work also provides empirical evidence that the proposed denoising strategy enhances the prediction accuracy of brain tumors by nearly 23%. The developed denoising technique using U-Net would benefit radiologists and computer-aided diagnostic systems (CAD) in precisely diagnosing the disease by generating cleaner and clearer MRI scans.","tags":[],"title":"MRI image denoising using U-Net and Image Processing Techniques","type":"publication"},{"authors":["Utsavi Jiten Visaria","Abhishek Mazumdar","Bharati Singh"],"categories":null,"content":"","date":1666915200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666915200,"objectID":"64267d721da4ff07509eb9974b323774","permalink":"https://example.com/publication/cataract/","publishdate":"2022-10-28T00:00:00Z","relpermalink":"/publication/cataract/","section":"publication","summary":"According to multiple authoritative authorities, including the World Health Organization, vision-related impairments and disorders are becoming a significant issue. According to a recent report, one of the leading causes of irreversible blindness in persons over the age of 50 is delayed cataract treatment. A cataract is a cloudy spot in the eye's lens that causes visual loss. Cataracts often develop slowly and consequently result in difficulty in driving, reading, and even recognizing faces. This necessitates the development of rapid and dependable diagnosis and treatment solutions for ocular illnesses. Previously, such visual illness diagnosis were done manually, which was time-consuming and prone to human mistake. However, as technology advances, automated, computer-based methods that decrease both time and human labor while producing trustworthy results are now accessible. In this study, we developed a CNN-LSTM-based model architecture with the goal of creating a low-cost diagnostic system that can classify normal and cataractous cases of ocular disease from fundus images. The proposed model was trained on the publicly available ODIR dataset, which included fundus images of patients' left and right eyes. The suggested architecture outperformed previous systems with a state-of-the-art 97.53% accuracy.","tags":[],"title":"A CNN-LSTM Combination Network for Cataract Detection using Eye Fundus Images","type":"publication"},{"authors":["Utsavi Jiten Visaria"],"categories":null,"content":"","date":1661817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661817600,"objectID":"86f68c11251b1472e9d8e6b8f4a181b3","permalink":"https://example.com/publication/helmet/","publishdate":"2022-08-30T00:00:00Z","relpermalink":"/publication/helmet/","section":"publication","summary":"Motorcycles are the most common mode of transport as they are affordable and low-maintenance vehicles. Motorcyclists were roughly 29 times more likely than passenger car passengers to die in an accident per vehicle mile travelled in 2019. One of the leading causes of fatal motorcycle accidents is the rider's failure to wear a helmet. According to section 129 of the motorcycle vehicle act, the Government has made it mandatory for two-wheeler drivers to wear helmets while driving. Still, many traffic rule violators do not obey them. In most developing countries, traffic police manually monitor motorcyclists at road junctions. Still, this method is inefficient as it does not apply on highways where the probability of accidents is highest due to speeding. This paper presents an automatic surveillance system for detecting two-wheeler drivers without helmets and recognizes their License plate numbers in the system. Firstly, the system detects motorcycles in the image or live video using the You Only Look Once (YOLO) algorithm. It again applies this algorithm to detect whether the driver is helmeted or not for the detected motorcycles. Finally, the motorcycle's number plate is detected for identified motorcyclists without a helmet, and the characters are extracted using Optical Character Recognition.","tags":[],"title":"Detection and Number Plate Recognition of Non-Helmeted Motorcyclists using YOLO","type":"publication"},{"authors":["Utsavi Jiten Visaria","Darshil Mehta","Kaushik Metha","Anoushka Bhat","Pragya Gupta","Ninad Mehendale"],"categories":null,"content":"","date":1661299200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661299200,"objectID":"2a4263a205f4f27f16680977971b38a6","permalink":"https://example.com/publication/alzheimer/","publishdate":"2022-08-24T00:00:00Z","relpermalink":"/publication/alzheimer/","section":"publication","summary":"Diagnosis of Alzheimer's disease is a challenging task, and detection can potentially help prevent its progression toward Dementia. Computer-aided techniques incorporating artificial intelligence have proven effective for diagnosing medical images. Deep learning tools like convolutional neural networks assist in extracting relevant visual information and thus avoiding manual feature extraction and interpretation. In this research, we propose a novel 3D-CNN model for the early detection of AD using positron emission tomography (PET). The dataset acquired from ADNI consists of 3D images of the brain segregated into three classes, namely Alzheimer's Disease (AD), Mild-Cognitive Impairment (MCI), and Cognitive Normal (CN). After data acquisition, we performed various pre-processing methods like thresholding, normalization, volume-reduction, and image augmentation. This study performed two types of experiments: multi-class and binary classification. The multi-class classification achieved an accuracy of 92.31%. Furthermore, the accuracy for AD vs CN, CN vs MCI, and MCI vs AD was 94.79%, 93.28%, and 96.91%, respectively.","tags":[],"title":"DeepPET-3D: A Deep Learning Based 3D-CNN Model for Diagnosis of Alzheimer's Disease Using 18-FDG-PET","type":"publication"},{"authors":null,"categories":null,"content":"","date":1651017600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1651017600,"objectID":"ed62e96b067d54a0b4f4689410286166","permalink":"https://example.com/project/diagnosys/","publishdate":"2022-04-27T00:00:00Z","relpermalink":"/project/diagnosys/","section":"project","summary":"Web-based diagnostic system to detect brain tumors from MRI scans and cataracts from fundus images of the eye. Developed a CNN-LSTM model for cataract detection and fine-tuned an EfficientNet-3 model for brain tumor classification.","tags":null,"title":"DiagnoSys.AI","type":"project"},{"authors":null,"categories":null,"content":"","date":1637798400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1637798400,"objectID":"aa143e2ec1811b8fd5f0077b9613a132","permalink":"https://example.com/project/image_captioning/","publishdate":"2021-11-25T00:00:00Z","relpermalink":"/project/image_captioning/","section":"project","summary":"Trained an Encoder-Decoder type model using a combination of InceptionV3 and LSTM model on the Flickr-8k dataset for generating sentence-based descriptions for an input image. Built a mobile application with the functionality of uploading an image and generating a caption.","tags":null,"title":"Image Captioning","type":"project"},{"authors":null,"categories":null,"content":"","date":1619481600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619481600,"objectID":"4c68fb5ee9e2607f93f1ef0c50a62855","permalink":"https://example.com/project/green_route/","publishdate":"2021-04-27T00:00:00Z","relpermalink":"/project/green_route/","section":"project","summary":"Every year, 86,000 people die due to delayed healthcare services. Green Route, a mobile app, helps ambulances move faster through traffic by alerting nearby Google Maps users within 1 km of the ambulance's path to clear the way for the ambulance.","tags":null,"title":"Green Route","type":"project"},{"authors":["Utsavi Jiten Visaria","吳恩達"],"categories":["Demo","教程"],"content":"import libr print(\u0026#39;hello\u0026#39;) Overview The Wowchemy website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site The template can be modified and customised to suit your needs. It’s a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a no-code solution (write in Markdown and customize with YAML parameters) and having flexibility to later add even deeper personalization with HTML and CSS You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more Get Started 👉 Create a new site 📚 Personalize your site 💬 Chat with the Wowchemy community or Hugo community 🐦 Twitter: @wowchemy @GeorgeCushen #MadeWithWowchemy 💡 Request a feature or report a bug for Wowchemy ⬆️ Updating Wowchemy? View the Update Tutorial and Release Notes Crowd-funded open-source software To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.\n❤️ Click here to become a sponsor and help support Wowchemy’s future ❤️ As a token of appreciation for sponsoring, you can unlock these awesome rewards and extra features 🦄✨\nEcosystem Hugo Academic CLI: Automatically import publications from BibTeX Inspiration Check out the latest demo of what you’ll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\nFeatures Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 34+ language packs including English, 中文, and Português Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files. Themes Wowchemy and its templates come with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\nChoose a stunning theme and font for your site. Themes are fully customizable.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://example.com/post/getting-started/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Welcome 👋 We know that first impressions are important, so we've populated your new site with some initial content to help you get familiar with everything in no time.","tags":["Academic","开源"],"title":"Welcome to Wowchemy, the website builder for Hugo","type":"post"},{"authors":null,"categories":null,"content":"","date":1585267200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585267200,"objectID":"28158908fa8e543183d649b19d7b2949","permalink":"https://example.com/project/hate_speech/","publishdate":"2020-03-27T00:00:00Z","relpermalink":"/project/hate_speech/","section":"project","summary":"Hateful and Offensive speech classification using 30k randomly extracted tweets from Twitter. Applied pre-processing techniques on tweets and designed an LSTM model for binary classification.","tags":null,"title":"Hateful Speech on Twitter","type":"project"},{"authors":null,"categories":null,"content":"Wowchemy is designed to give technical content creators a seamless experience. You can focus on the content and Wowchemy handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.\nOn this page, you’ll find some examples of the types of technical content that can be rendered with Wowchemy.\nExamples Code Wowchemy supports a Markdown extension for highlighting code syntax. You can customize the styles under the syntax_highlighter option in your config/_default/params.yaml file.\n```python import pandas as pd data = pd.read_csv(\u0026#34;data.csv\u0026#34;) data.head() ``` renders as\nimport pandas as pd data = pd.read_csv(\u0026#34;data.csv\u0026#34;) data.head() Mindmaps Wowchemy supports a Markdown extension for mindmaps.\nSimply insert a Markdown markmap code block and optionally set the height of the mindmap as shown in the example below.\nA simple mindmap defined as a Markdown list:\n```markmap {height=\u0026#34;200px\u0026#34;} - Hugo Modules - wowchemy - wowchemy-plugins-netlify - wowchemy-plugins-netlify-cms - wowchemy-plugins-reveal ``` renders as\n- Hugo Modules - wowchemy - wowchemy-plugins-netlify - wowchemy-plugins-netlify-cms - wowchemy-plugins-reveal A more advanced mindmap with formatting, code blocks, and math:\n```markmap - Mindmaps - Links - [Wowchemy Docs](https://wowchemy.com/docs/) - [Discord Community](https://discord.gg/z8wNYzb) - [GitHub](https://github.com/wowchemy/wowchemy-hugo-themes) - Features - Markdown formatting - **inline** ~~text~~ *styles* - multiline text - `inline code` - ```js console.log(\u0026#39;hello\u0026#39;); console.log(\u0026#39;code block\u0026#39;); ``` - Math: $x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}$ ``` renders as\n- Mindmaps - Links - [Wowchemy Docs](https://wowchemy.com/docs/) - [Discord Community](https://discord.gg/z8wNYzb) - [GitHub](https://github.com/wowchemy/wowchemy-hugo-themes) - Features - Markdown formatting - **inline** ~~text~~ *styles* - multiline text - `inline code` - ```js console.log(\u0026#39;hello\u0026#39;); console.log(\u0026#39;code block\u0026#39;); ``` - Math: $x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}$ Charts Wowchemy supports the popular Plotly format for interactive charts.\nSave your Plotly JSON in your page folder, for example line-chart.json, and then add the {{\u0026lt; chart data=\u0026#34;line-chart\u0026#34; \u0026gt;}} shortcode where you would like the chart to appear.\nDemo:\nYou might also find the Plotly JSON Editor useful.\nMath Wowchemy supports a Markdown extension for $\\LaTeX$ math. You can enable this feature by toggling the math option in your config/_default/params.yaml file.\nTo render inline or block math, wrap your LaTeX math with {{\u0026lt; math \u0026gt;}}$...${{\u0026lt; /math \u0026gt;}} or {{\u0026lt; math \u0026gt;}}$$...$${{\u0026lt; /math \u0026gt;}}, respectively. (We wrap the LaTeX math in the Wowchemy math shortcode to prevent Hugo rendering our math as Markdown. The math shortcode is new in v5.5-dev.)\nExample math block:\n{{\u0026lt; math \u0026gt;}} $$ \\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2} $$ {{\u0026lt; /math \u0026gt;}} renders as\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2}$$ Example inline math {{\u0026lt; math \u0026gt;}}$\\nabla F(\\mathbf{x}_{n})${{\u0026lt; /math \u0026gt;}} renders as $\\nabla F(\\mathbf{x}_{n})$.\nExample multi-line math using the math linebreak (\\\\):\n{{\u0026lt; math \u0026gt;}} $$f(k;p_{0}^{*}) = \\begin{cases}p_{0}^{*} \u0026amp; \\text{if }k=1, \\\\ 1-p_{0}^{*} \u0026amp; \\text{if }k=0.\\end{cases}$$ {{\u0026lt; /math \u0026gt;}} renders as\n$$ f(k;p_{0}^{*}) = \\begin{cases}p_{0}^{*} \u0026amp; \\text{if }k=1, \\\\ 1-p_{0}^{*} \u0026amp; \\text{if }k=0.\\end{cases} $$ Diagrams Wowchemy supports a Markdown extension for diagrams. You can enable this feature by toggling the diagram option in your config/_default/params.toml file or by adding diagram: true to your page front matter.\nAn example flowchart:\n```mermaid graph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2] ``` renders as\ngraph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2] An example sequence diagram:\n```mermaid sequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good! ``` renders as\nsequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good! An example Gantt diagram:\n```mermaid gantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d ``` renders …","date":1562889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562889600,"objectID":"07e02bccc368a192a0c76c44918396c3","permalink":"https://example.com/post/writing-technical-content/","publishdate":"2019-07-12T00:00:00Z","relpermalink":"/post/writing-technical-content/","section":"post","summary":"Wowchemy is designed to give technical content creators a seamless experience. You can focus on the content and Wowchemy handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.","tags":null,"title":"Writing technical content in Markdown","type":"post"},{"authors":["Utsavi Jiten Visaria"],"categories":[],"content":"from IPython.core.display import Image Image(\u0026#39;https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png\u0026#39;) print(\u0026#34;Welcome to Academic!\u0026#34;) Welcome to Academic! Install Python and JupyterLab Install Anaconda which includes Python 3 and JupyterLab.\nAlternatively, install JupyterLab with pip3 install jupyterlab.\nCreate or upload a Jupyter notebook Run the following commands in your Terminal, substituting \u0026lt;MY-WEBSITE-FOLDER\u0026gt; and \u0026lt;SHORT-POST-TITLE\u0026gt; with the file path to your Academic website folder and a short title for your blog post (use hyphens instead of spaces), respectively:\nmkdir -p \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ cd \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ jupyter lab index.ipynb The jupyter command above will launch the JupyterLab editor, allowing us to add Academic metadata and write the content.\nEdit your post metadata The first cell of your Jupter notebook will contain your post metadata (front matter).\nIn Jupter, choose Markdown as the type of the first cell and wrap your Academic metadata in three dashes, indicating that it is YAML front matter:\n--- title: My post\u0026#39;s title date: 2019-09-01 # Put any other Academic metadata here... --- Edit the metadata of your post, using the documentation as a guide to the available options.\nTo set a featured image, place an image named featured into your post’s folder.\nFor other tips, such as using math, see the guide on writing content with Academic.\nConvert notebook to Markdown jupyter nbconvert index.ipynb --to markdown --NbConvertApp.output_files_dir=. Example This post was created with Jupyter. The orginal files can be found at https://github.com/gcushen/hugo-academic/tree/master/exampleSite/content/post/jupyter\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567641600,"objectID":"6e929dc84ed3ef80467b02e64cd2ed64","permalink":"https://example.com/post/jupyter/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/post/jupyter/","section":"post","summary":"Learn how to blog in Academic using Jupyter notebooks","tags":[],"title":"Display Jupyter Notebooks with Academic","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://example.com/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Kush Vora","Utsavi Jiten Visaria"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"4ff7a5525a0bfb9a831e222f614e9e09","permalink":"https://example.com/publication/plant_disease/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/plant_disease/","section":"publication","summary":"Apple diseases, if not diagnosed early, can lead to massive resource loss and pose a serious threat to humans and animals who consume the infected apples. Hence, it is critical to diagnose these diseases early in order to manage plant health and minimize the risks associated with them. However, the conventional approach of monitoring plant diseases entails manual scouting and analyzing the features, texture, color, and shape of the plant leaves, resulting in delayed diagnosis and misjudgments. Our work proposes an ensembled system of Xception, InceptionResNet, and MobileNet architectures to detect 5 different types of apple plant diseases. The model has been trained on the publicly available Plant Pathology 2021 dataset and can classify multiple diseases in a given plant leaf. The system has achieved outstanding results in multi-class and multi-label classification and can be used in a real-time setting to monitor large apple plantations to aid the farmers manage their yields effectively.","tags":[],"title":"An Ensemble of Convolutional Neural Networks to Detect Foliar Diseases in Apple Plants","type":"publication"}]